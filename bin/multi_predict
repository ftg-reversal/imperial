#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#  Imperial
#  ======
#  Copyright (C) 2015 FTG-Reversal
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import sys
import os
import cv2
import numpy as np

sys.path.append('.')
video_id = sys.argv[1]

import imperial.constants
from imperial import CharaRecoginizer

charas = [
    ("アクセル","ax"),
    ("ベッドマン","be"),
    ("チップ","ch"),
    ("エルフェルト","el"),
    ("ファウスト", "fa"),
    ("イノ", "in"),
    ("ジャム", "ja"),
    ("ジャックオー", "jc"),
    ("ジョニー", "jo"),
    ("カイ", "ky"),
    ("レオ", "le"),
    ("メイ", "ma"),
    ("ミリア", "mi"),
    ("ポチョムキン", "po"),
    ("ラムレザル", "ra"),
    ("シン", "si"),
    ("スレイヤー", "sl"),
    ("ソル", "so"),
    ("ヴェノム", "ve"),
    ("ザトー", "za")
]

def fetch_data(video_id, fetch_dir):
    if not os.path.isdir(fetch_dir):
        os.mkdir(fetch_dir)
        os.mkdir(fetch_dir + "/1p")
        os.mkdir(fetch_dir + "/2p")
        os.system("nicovideo-dump http://www.nicovideo.jp/watch/" + video_id + " | ffmpeg -i pipe:0 -filter_complex '[0:v]fps=1, scale=640:-1, split[tmp1][tmp2]; [tmp1]crop=40:40:20:0[out1]; [tmp2]crop=40:40:580:0[out2]' -map '[out1]' " + fetch_dir + "/1p/%04d.jpg -map '[out2]' " + fetch_dir + "/2p/%04d.jpg")

def read_fetched_data(fetch_dir, player):
    files = sorted(os.listdir(fetch_dir + '/' + player))
    distances = np.empty((len(imperial.constants.charas), len(files)))

    for chara_index, chara in enumerate(imperial.constants.charas):
        recoginizer = CharaRecoginizer()
        recoginizer.load_model_from_file(player, str(chara_index))
        recoginizer.knn_train()

        arr = np.array([])
        for file_index, file in enumerate(files):
            img = cv2.imread(fetch_dir + '/' + player + '/' + file)
            assert img is not None

            result, distance = recoginizer.predict(img)
            arr = np.append(arr, distance)

        distances[chara_index] = arr

    return distances

def convolve(distances, size):
    convolved_list = np.array(distances)
    g_last  = np.array([ *[0.] * (size - 1), 1 / size, *[ 1 / size ] * (size - 1) ])
    g_first = np.array([ *[ 1 / size ] * (size - 1), 1 / size, *[0.] * (size - 1) ])

    for i, distance in enumerate(distances):
        last = np.convolve(distance, g_last, 'same')
        first = np.convolve(distance, g_first, 'same')

        # lastの先頭とfirstの終端に異常に小さな値が入ってしまうのを修正する
        # TODO: 上手くいってない気がする
        for j in range(size - 1):
            last[j] = last[j] / (j + 1) * (size - (j + 1))
        for j in range(size - 1):
            first[len(first - j) - 1] = first[len(first - j) - 1] / (j + 1) * (size - (j + 1))

        convolved_list[i] = np.min([last, first], axis=0)

    return convolved_list


def distances_to_scores(distances):
    scores = np.empty((0, 2), dtype=np.float32)
    for score in distances.T:
        scores = np.append(scores, np.array([[np.argmin(score), np.amin(score)]]), axis=0)

    return scores

def reduce_pair_func(reducer, pair):
    # numpyのbool配列が返ってくる
    boolean = reducer[-1][1][0] == pair[1][0]

    if boolean[0] == True and boolean[1] == True:
        return

    reducer.append(pair)

def id2name(id):
    return charas[id][0]

fetch_data(video_id, './fetched_data/' + video_id, '1p')

# 1Pと2Pのデータを20次元のデータとしてそれぞれ読み込む
distances_1p = read_fetched_data('./fetched_data/' + video_id, '1p')
distances_2p = read_fetched_data('./fetched_data/' + video_id, '2p')

# 1Pと2Pのデータを各キャラ毎にたたみ込む
convolved_distances_1p = convolve(distances_1p, 20)
convolved_distances_2p = convolve(distances_2p, 20)

# フレーム毎の最も近いキャラと距離のペアをスコアとして扱う
scores_1p = distances_to_scores(convolved_distances_1p)
scores_2p = distances_to_scores(convolved_distances_2p)

# フレーム毎のスコアを1Pと2PでまとめてキャラIDとスコアのペアが入ったリストを作る
zip_scores = np.dstack((scores_1p, scores_2p))

# スコアが一定以下のものを真として各フレーム毎の対戦組み合わせのリストを生成する
pairs = []
for sec, score in enumerate(zip_scores):
    if score[1][0] + score[1][1] < 100:
        pairs.append((sec, score))

# 連続したフレームに残っている組み合わせを畳み込む
reducer = [pairs[0]]
for pair in pairs:
    reduce_pair_func(reducer, pair)

# 特定のフレーム以下しか存在しないペアを削除する
index = 1
while True:
    if len(reducer) - 1 < index:
        break
    if reducer[index][0] - reducer[index - 1][0] < 60:
        del reducer[index - 1]
    else:
        index += 1
reducer.pop()

for pair in reducer:
    print('sec: ' + str(pair[0]) + ', ' + id2name(int(pair[1][0][0])) + ' vs ' + id2name(int(pair[1][0][1])))
