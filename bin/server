#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#  Imperial
#  ======
#  Copyright (C) 2015 FTG-Reversal
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import sys
import os
import cv2
import numpy as np
import re
import json
from flask import Flask
from flask import abort

sys.path.append('.')

import imperial.constants
from imperial import CharaRecoginizer

CHARAS = [
    ("Axl","ax"),
    ("Bedman","be"),
    ("Chipp","ch"),
    ("Elphelt","el"),
    ("Faust", "fa"),
    ("I-no", "in"),
    ("Jam", "ja"),
    ("Jack-O", "jc"),
    ("Johnny", "jo"),
    ("Ky", "ky"),
    ("Leo", "le"),
    ("May", "ma"),
    ("Millia", "mi"),
    ("Potemkin", "po"),
    ("Ramlethal", "ra"),
    ("Sin", "si"),
    ("Slayer", "sl"),
    ("Sol", "so"),
    ("Venom", "ve"),
    ("Zato", "za")
]

def fetch_data(video_id, fetch_dir):
    if not os.path.isdir(fetch_dir):
        os.mkdir(fetch_dir)
        os.mkdir(fetch_dir + "/1p")
        os.mkdir(fetch_dir + "/2p")
        os.system("nicovideo-dump http://www.nicovideo.jp/watch/" + video_id + " | ffmpeg -i pipe:0 -filter_complex '[0:v]fps=1, scale=640:-1, split[tmp1][tmp2]; [tmp1]crop=40:40:20:0[out1]; [tmp2]crop=40:40:580:0[out2]' -map '[out1]' " + fetch_dir + "/1p/%04d.jpg -map '[out2]' " + fetch_dir + "/2p/%04d.jpg")

def read_fetched_data(fetch_dir, player):
    files = sorted(os.listdir(fetch_dir + '/' + player))
    distances = np.empty((len(imperial.constants.charas), len(files)))

    for chara_index, chara in enumerate(imperial.constants.charas):
        recoginizer = CharaRecoginizer()
        recoginizer.load_model_from_file(player, str(chara_index))
        recoginizer.knn_train()

        arr = np.array([])
        for file_index, file in enumerate(files):
            img = cv2.imread(fetch_dir + '/' + player + '/' + file)
            assert img is not None

            result, distance = recoginizer.predict(img)
            arr = np.append(arr, distance)

        distances[chara_index] = arr

    return distances

def convolve(distances, size):
    convolved_list = np.array(distances)
    g_last  = np.array([ *[0.] * (size - 1), 1 / size, *[ 1 / size ] * (size - 1) ])
    g_first = np.array([ *[ 1 / size ] * (size - 1), 1 / size, *[0.] * (size - 1) ])

    for i, distance in enumerate(distances):
        last = np.convolve(distance, g_last, 'same')
        first = np.convolve(distance, g_first, 'same')

        # lastの先頭とfirstの終端に異常に小さな値が入ってしまうのを修正する
        # TODO: 上手くいってない気がする
        for j in range(size - 1):
            last[j] = last[j] / (j + 1) * (size - (j + 1))
        for j in range(size - 1):
            first[len(first - j) - 1] = first[len(first - j) - 1] / (j + 1) * (size - (j + 1))

        convolved_list[i] = np.min([last, first], axis=0)

    return convolved_list


def distances_to_scores(distances):
    scores = np.empty((0, 2), dtype=np.float32)
    for score in distances.T:
        scores = np.append(scores, np.array([[np.argmin(score), np.amin(score)]]), axis=0)

    return scores

def reduce_pair_func(reducer, pair):
    # numpyのbool配列が返ってくる
    boolean = reducer[-1][1][0] == pair[1][0]

    if boolean[0] == True and boolean[1] == True:
        return

    reducer.append(pair)

def id2name(id):
    return CHARAS[id][0]

#  アプリ初期化
server = Flask(__name__)
@server.route('/<score_threshold>/<frame_threshold>/<video_id>', methods=['GET'])

def predict(score_threshold, frame_threshold, video_id):
    if not re.match('^sm\d+$', video_id):
        return abort(500)

    fetch_data(video_id, './fetched_data/' + video_id)

    # 1Pと2Pのデータを20次元のデータとしてそれぞれ読み込む
    distances_1p = read_fetched_data('./fetched_data/' + video_id, '1p')
    distances_2p = read_fetched_data('./fetched_data/' + video_id, '2p')

    # 1Pと2Pのデータを各キャラ毎にたたみ込む
    convolved_distances_1p = convolve(distances_1p, 20)
    convolved_distances_2p = convolve(distances_2p, 20)

    # フレーム毎の最も近いキャラと距離のペアをスコアとして扱う
    scores_1p = distances_to_scores(convolved_distances_1p)
    scores_2p = distances_to_scores(convolved_distances_2p)

    # フレーム毎のスコアを1Pと2PでまとめてキャラIDとスコアのペアが入ったリストを作る
    zip_scores = np.dstack((scores_1p, scores_2p))

    # スコアが一定以下のものを真として各フレーム毎の対戦組み合わせのリストを生成する
    pairs = []
    for sec, score in enumerate(zip_scores):
        if score[1][0] + score[1][1] < int(score_threshold):
            pairs.append((sec, score))

    # 連続したフレームに残っている組み合わせを畳み込む
    reducer = [pairs[0]]
    for pair in pairs:
        reduce_pair_func(reducer, pair)

    # 特定のフレーム以下しか存在しないペアを削除する
    index = len(reducer) - 1
    while True:
        if index == 1:
            break
        if reducer[index][0] - reducer[index - 1][0] < int(frame_threshold):
            del reducer[index - 1]
        index -= 1

    # 先頭の要素を削除
    reducer.pop(0)

    # reducerの最後の要素が特定フレーム以下の長さなら削除
    while True:
        if len(os.listdir('./fetched_data/' + video_id+ '/1p')) - reducer[-1][0] < int(frame_threshold):
            reducer.pop()
        else:
            break

    pairs = []
    for pair in reducer:
        dict = {}
        dict['sec'] = pair[0]
        # TODO: pairオブジェクトが無駄に1階層深くなってしまってる
        dict['1p'] = id2name(int(pair[1][0][0]))
        dict['2p'] = id2name(int(pair[1][0][1]))
        pairs.append(dict)
        print('sec: ' + str(pair[0]) + ', ' + id2name(int(pair[1][0][0])) + ' vs ' + id2name(int(pair[1][0][1])))

    return json.dumps(pairs, ensure_ascii=False)

if __name__ == '__main__':
    server.run(host='0.0.0.0', debug=True, port=80)
